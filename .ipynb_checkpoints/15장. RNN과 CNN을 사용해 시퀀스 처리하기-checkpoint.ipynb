{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 시계열 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사인함수로 시계열 데이터 만들기\n",
    "\n",
    "def generate_time_series(batch_size, n_steps):\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    series = 0.5 * np.sin(((time - offsets1) * (freq1 * 10 + 10)))  # 사인 곡선1\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20))  # 사인 곡선2\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)    # 잡음\n",
    "    return series[..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, n_steps], series[9000:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 기준 성능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Forcasting (각 시계열의 마지막 값을 그대로 예측하는 것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020365203"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# naive forcasting \n",
    "\n",
    "y_pred = X_valid[:, -1]\n",
    "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 완전 연결 네트워크 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완전 연결 네트워크 사용하기\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[50, 1]),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0941\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0330\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 0s 989us/step - loss: 0.0210\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 0s 784us/step - loss: 0.0159\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0134A: 0s - loss: 0.01\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 0s 815us/step - loss: 0.0117\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 0s 818us/step - loss: 0.0105\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 0s 856us/step - loss: 0.0094\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 0s 842us/step - loss: 0.0086\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 0s 965us/step - loss: 0.0078\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0072\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 0s 867us/step - loss: 0.0067\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 0s 955us/step - loss: 0.0063\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 0s 998us/step - loss: 0.0059\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 0s 874us/step - loss: 0.0056\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 0s 915us/step - loss: 0.0054\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0052\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 0s 868us/step - loss: 0.0048\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 0s 852us/step - loss: 0.0046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c284828d08>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 947us/step - loss: 0.0049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.004870355594903231"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 간단한 RNN 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.4450\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.3962\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.3518\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.3089\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.2681\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.2303\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1966\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1683\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1457\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1277\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1134\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0980\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0790\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0630\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0503\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0399\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0315\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0249\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0200\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c285df8948>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.015127567574381828"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid) \n",
    "\n",
    "# 완전 연결 층보다 성능이 좋진 않지만 파라미터가 3개만 쓰였음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) 심층 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleRNN 여러 층으로 쌓기 (활성화 함수 : tanh)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 활성화 함수를 사용하기 위해 출력층을 Dense층으로\n",
    "# 이를 위해 이제는 마지막 순환층이 된 두번째 층에서 return_sequences=True 제거해야\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) 여러 타임 스텝 앞 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (방법1) 예측값을 다음 스텝의 입력값으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_time_series(1, n_steps + 10)\n",
    "X_new, y_new = series[:, :n_steps], series[:, n_steps:]\n",
    "X = X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step_ahead in range(10):\n",
    "    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]\n",
    "    X = np.concatenate([X, y_pred_one], axis=1)\n",
    "    \n",
    "Y_pred = X[:, n_steps:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.23082507],\n",
       "        [-0.14905705],\n",
       "        [ 0.0492443 ],\n",
       "        [ 0.2805521 ],\n",
       "        [ 0.5279423 ],\n",
       "        [ 0.6124417 ],\n",
       "        [ 0.75798327],\n",
       "        [ 0.82106704],\n",
       "        [ 0.77922845],\n",
       "        [ 0.6122835 ]]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (방법2) RNN을 훈련하여 다음 값 10개를 한 번에 예측\n",
    ": 시퀀스-투-벡터 모델 (마지막 스텝에서만 다음 값 10개 예측)\n",
    "<img src='img/15_1.png' width='200'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_time_series(10000, n_steps + 10)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -10:, 0]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -10:, 0]\n",
    "\n",
    "# X에 대해서는 [, , 0] 안 하고 y에 대해서만 해서\n",
    "# X에 대해서는 2차원 리스트로 만들고 [[1], [2], ..., [n_steps]]\n",
    "# y에 대해서는 그냥 1차원 리스트로 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(10)    # 10개의 유닛을 가진 출력층\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 14s 64ms/step - loss: 0.0392 - val_loss: 0.0080\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 10s 48ms/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 10s 47ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 14s 62ms/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 18s 81ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 13s 60ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 12s 57ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 15s 66ms/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 19s 88ms/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 20s 92ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 14s 62ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 11s 50ms/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 11s 51ms/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 11s 51ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 14s 66ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 14s 65ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 14s 65ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 11s 49ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 10s 46ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 11s 52ms/step - loss: 0.0029 - val_loss: 0.0029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1caedb6bc88>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4745298 , 0.44532877, 0.44909075, 0.43029204, 0.47094586,\n",
       "        0.45882994, 0.4321749 , 0.43762532, 0.46150336, 0.43843722]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred   # MSE 0.008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (방법3) Sequence-to-Sequence RNN\n",
    ": 모든 타임 스텝에서 다음 값 10개를 예측하는 모델\n",
    "<img src='img/15_2.png' width='180'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타깃 시퀀스 만들기 (입력 시퀀스와 동일한 길이의 시퀀스)\n",
    "\n",
    "Y = np.empty((10000, n_steps, 10))  # 10D벡터의 시퀀스 (0으로 채우기)\n",
    "for step_ahead in range(1, 10 + 1):\n",
    "    Y[:, :, step_ahead - 1] = series[:, step_ahead:(step_ahead + n_steps), 0]\n",
    "\n",
    "y_train = Y[:7000]\n",
    "y_valid = Y[7000:9000]\n",
    "y_test = Y[9000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 50, 10)\n",
      "(7000, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)   # 10차원의 시퀀스 50개\n",
    "print(X_train.shape)  # 50개의 시퀀스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "# TimeDistributed 층 : 다른 층(Dense 층)을 감싸서 입력 시퀀스의 모든 타임 스텝에\n",
    "# 적용 (사실 Dense 층이 시퀀스를 입력으로 받을 수 있어 그냥 Dense(10)로 해도 됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가하기\n",
    "# 훈련할 떄는 모든 스텝이 필요하지만, 평가에는 마지막 타임 스텝의 출력만 필요\n",
    "# -> 마지막 타임 스텝의 출력에 대한 MSE만 계산하는 함수 만듦\n",
    "\n",
    "def last_time_step_mse(Y_true, Y_pred):\n",
    "    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=0.01)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=[last_time_step_mse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0496 - last_time_step_mse: 0.0388 - val_loss: 0.0428 - val_last_time_step_mse: 0.0326\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 0.0368 - last_time_step_mse: 0.0248 - val_loss: 0.0336 - val_last_time_step_mse: 0.0224\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 0.0316 - last_time_step_mse: 0.0196 - val_loss: 0.0287 - val_last_time_step_mse: 0.0153\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 0.0287 - last_time_step_mse: 0.0168 - val_loss: 0.0265 - val_last_time_step_mse: 0.0139\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0267 - last_time_step_mse: 0.0150 - val_loss: 0.0254 - val_last_time_step_mse: 0.0136\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 0.0242 - last_time_step_mse: 0.0122 - val_loss: 0.0234 - val_last_time_step_mse: 0.0113\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 0.0226 - last_time_step_mse: 0.0105 - val_loss: 0.0214 - val_last_time_step_mse: 0.0097\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 0.0210 - last_time_step_mse: 0.0089 - val_loss: 0.0229 - val_last_time_step_mse: 0.0111\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 0.0209 - last_time_step_mse: 0.0090 - val_loss: 0.0202 - val_last_time_step_mse: 0.0083\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 0.0203 - last_time_step_mse: 0.0085 - val_loss: 0.0201 - val_last_time_step_mse: 0.0081\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 7s 31ms/step - loss: 0.0208 - last_time_step_mse: 0.0089 - val_loss: 0.0213 - val_last_time_step_mse: 0.0100\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0195 - last_time_step_mse: 0.0076 - val_loss: 0.0207 - val_last_time_step_mse: 0.0093\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 6s 27ms/step - loss: 0.0199 - last_time_step_mse: 0.0080 - val_loss: 0.0211 - val_last_time_step_mse: 0.0105\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 6s 29ms/step - loss: 0.0191 - last_time_step_mse: 0.0072 - val_loss: 0.0193 - val_last_time_step_mse: 0.0073\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 6s 27ms/step - loss: 0.0244 - last_time_step_mse: 0.0133 - val_loss: 0.0351 - val_last_time_step_mse: 0.0259\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.0280 - last_time_step_mse: 0.0176 - val_loss: 0.0269 - val_last_time_step_mse: 0.0166\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 6s 25ms/step - loss: 0.0217 - last_time_step_mse: 0.0105 - val_loss: 0.0212 - val_last_time_step_mse: 0.0097\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0230 - last_time_step_mse: 0.0126 - val_loss: 0.0200 - val_last_time_step_mse: 0.0092\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0201 - last_time_step_mse: 0.0089 - val_loss: 0.0196 - val_last_time_step_mse: 0.0087\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 4s 18ms/step - loss: 0.0194 - last_time_step_mse: 0.0083 - val_loss: 0.0185 - val_last_time_step_mse: 0.0076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1caf296bd88>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0186 - last_time_step_mse: 0.0075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01863916777074337, 0.007499366067349911]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)   # MSE 0.006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 긴 시퀀스 다루기\n",
    "#### 1) 불안정한 그레디언트\n",
    "- 수렴하는 활성화 함수 사용하기\n",
    "- 층 정규화\n",
    "- 드롭아웃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 층 정규화\n",
    "\n",
    "class LNSimpleRNNCell(keras.layers.Layer):\n",
    "    def __init__(self, units, activation='tanh', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.state_size = units\n",
    "        self.output_size = units\n",
    "        self.simple_rnn_cell = keras.layers.SimpleRNNCell(units,\n",
    "                                                         activation=None)\n",
    "        self.layer_norm = keras.layers.LayerNormalization()\n",
    "        self.activation = keras.activations.get(activation)\n",
    "    \n",
    "    def call(self, inputs, states):\n",
    "        outputs, new_states = self.simple_rnn_cell(inputs, states)\n",
    "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
    "        return norm_outputs, [norm_outputs]  # 두 값을 반환 (은닉상태와 출력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True,\n",
    "                    input_shape=[None, 1]),\n",
    "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "# 드롭 아웃은 dropout(입력 드롭아웃 비율)과 recurrent_dropout 옵션(은닉 상태\n",
    "# 드롭아웃 비율)으로 설정가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 단기 기억 문제 해결하기\n",
    "- LSTM 셀\n",
    "- Peephole 연결\n",
    "- GRU 셀\n",
    "- 1D 합성곱층 사용하기\n",
    "- WaveNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.LSTM(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN층에 LSTMCell을 매개변수로 지정할 수도 있음 (위와 같은 코드)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.RNN(keras.layers.LSTMCell(20), return_sequences=True,\n",
    "                    input_shape=[None, 1]),\n",
    "    keras.layers.RNN(keras.layers.LSTMCell(20), return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1D 합성곱 층을 사용해 시퀀스 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding='valid',\n",
    "                       input_shape=[None, 1]),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=optimizer, metrics=[last_time_step_mse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0355 - last_time_step_mse: 0.0280 - val_loss: 0.0190 - val_last_time_step_mse: 0.0086\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 4s 18ms/step - loss: 0.0168 - last_time_step_mse: 0.0066 - val_loss: 0.0152 - val_last_time_step_mse: 0.0056\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0145 - last_time_step_mse: 0.0050 - val_loss: 0.0137 - val_last_time_step_mse: 0.0043\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0135 - last_time_step_mse: 0.0044 - val_loss: 0.0140 - val_last_time_step_mse: 0.0049\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 4s 19ms/step - loss: 0.0129 - last_time_step_mse: 0.0040 - val_loss: 0.0128 - val_last_time_step_mse: 0.0042\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0124 - last_time_step_mse: 0.0037 - val_loss: 0.0127 - val_last_time_step_mse: 0.0042\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0121 - last_time_step_mse: 0.0036 - val_loss: 0.0121 - val_last_time_step_mse: 0.0032\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0118 - last_time_step_mse: 0.0034 - val_loss: 0.0118 - val_last_time_step_mse: 0.0035\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.0117 - last_time_step_mse: 0.0034 - val_loss: 0.0119 - val_last_time_step_mse: 0.0039\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 7s 31ms/step - loss: 0.0116 - last_time_step_mse: 0.0033 - val_loss: 0.0117 - val_last_time_step_mse: 0.0034\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 0.0113 - last_time_step_mse: 0.0033 - val_loss: 0.0111 - val_last_time_step_mse: 0.0029\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0111 - last_time_step_mse: 0.0031 - val_loss: 0.0112 - val_last_time_step_mse: 0.0032\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0111 - last_time_step_mse: 0.0032 - val_loss: 0.0111 - val_last_time_step_mse: 0.0030\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 0.0109 - last_time_step_mse: 0.0030 - val_loss: 0.0112 - val_last_time_step_mse: 0.0033\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0109 - last_time_step_mse: 0.0030 - val_loss: 0.0107 - val_last_time_step_mse: 0.0027\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 7s 31ms/step - loss: 0.0108 - last_time_step_mse: 0.0030 - val_loss: 0.0118 - val_last_time_step_mse: 0.0043\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0107 - last_time_step_mse: 0.0030 - val_loss: 0.0113 - val_last_time_step_mse: 0.0030\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 6s 28ms/step - loss: 0.0106 - last_time_step_mse: 0.0029 - val_loss: 0.0107 - val_last_time_step_mse: 0.0028\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 6s 28ms/step - loss: 0.0106 - last_time_step_mse: 0.0029 - val_loss: 0.0106 - val_last_time_step_mse: 0.0029\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 7s 30ms/step - loss: 0.0105 - last_time_step_mse: 0.0029 - val_loss: 0.0114 - val_last_time_step_mse: 0.0042\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train[:, 3::2], epochs=20,\n",
    "                    validation_data=(X_valid, y_valid[:, 3::2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WAVENET\n",
    "- 이 네트워크는 층마다 팽창 비율(각 뉴런의 입력이 떨어져 있는 간격)을 두 배로 늘리는 1D 합성곱 층을 쌓음\n",
    "- 하위층은 단기 패턴을 학습하고 상위층은 장기 패턴을 효율적으로 학습\n",
    "- 각 층 이전의 팽창 비율과 동일한 개수의 0을 입력 시퀀스 왼쪽에 패딩으로 추가 (causal padding) -> 다음 값을 훔쳐보지 않도록!\n",
    "<img src='img/15_3.png' width='350'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=[None, 1]))  # 입력층 \n",
    "                                                       # for문 안에 넣기엔 복잡\n",
    "for rate in (1, 2, 4, 8) * 2:  # 1, 2, 4, 8 반복\n",
    "    model.add(keras.layers.Conv1D(filters=20, kernel_size=2, padding='causal',\n",
    "                                 activation='relu', dilation_rate=rate))\n",
    "    \n",
    "model.add(keras.layers.Conv1D(filters=10, kernel_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=[last_time_step_mse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.0657 - last_time_step_mse: 0.0543 - val_loss: 0.0360 - val_last_time_step_mse: 0.0228\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0320 - last_time_step_mse: 0.0196 - val_loss: 0.0295 - val_last_time_step_mse: 0.0175\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0282 - last_time_step_mse: 0.0162 - val_loss: 0.0277 - val_last_time_step_mse: 0.0154\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0263 - last_time_step_mse: 0.0143 - val_loss: 0.0256 - val_last_time_step_mse: 0.0136\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0250 - last_time_step_mse: 0.0130 - val_loss: 0.0247 - val_last_time_step_mse: 0.0127\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0241 - last_time_step_mse: 0.0122 - val_loss: 0.0241 - val_last_time_step_mse: 0.0125\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0235 - last_time_step_mse: 0.0116 - val_loss: 0.0232 - val_last_time_step_mse: 0.0115\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0228 - last_time_step_mse: 0.0109 - val_loss: 0.0229 - val_last_time_step_mse: 0.0109\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0224 - last_time_step_mse: 0.0105 - val_loss: 0.0222 - val_last_time_step_mse: 0.0105\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0220 - last_time_step_mse: 0.0103 - val_loss: 0.0219 - val_last_time_step_mse: 0.0103\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0217 - last_time_step_mse: 0.0099 - val_loss: 0.0219 - val_last_time_step_mse: 0.0104\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0214 - last_time_step_mse: 0.0098 - val_loss: 0.0220 - val_last_time_step_mse: 0.0109\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0210 - last_time_step_mse: 0.0094 - val_loss: 0.0213 - val_last_time_step_mse: 0.0097\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.0208 - last_time_step_mse: 0.0091 - val_loss: 0.0210 - val_last_time_step_mse: 0.0097\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0205 - last_time_step_mse: 0.0089 - val_loss: 0.0212 - val_last_time_step_mse: 0.0094\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0204 - last_time_step_mse: 0.0087 - val_loss: 0.0201 - val_last_time_step_mse: 0.0084\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0202 - last_time_step_mse: 0.0086 - val_loss: 0.0204 - val_last_time_step_mse: 0.0088\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0200 - last_time_step_mse: 0.0084 - val_loss: 0.0201 - val_last_time_step_mse: 0.0084\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0197 - last_time_step_mse: 0.0081 - val_loss: 0.0202 - val_last_time_step_mse: 0.0090\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0195 - last_time_step_mse: 0.0080 - val_loss: 0.0198 - val_last_time_step_mse: 0.0083\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                   validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
