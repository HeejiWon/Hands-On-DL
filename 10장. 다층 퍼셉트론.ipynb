{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(X_train_full.shape)\n",
    "print(X_train_full.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증셋 만들기 & 정규화(0~255 -> 0~1)\n",
    "\n",
    "X_valid, X_train = X_train_full[:50000]/255.0, X_train_full[50000:]/255.0\n",
    "y_valid, y_train = y_train_full[:50000], y_train_full[50000:]\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 달기\n",
    "\n",
    "class_names = [\"T-shirt/top\",'Trouser','Pullover','Dress','Coat','Sandal',\n",
    "              'Shirt','Sneaker','Bag','Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 시퀀셜 API를 사용하여 이미지 분류기\n",
    "- .Flatten() : 이 층은 파라미터를 가지지 않고 간단한 전처리 수행(.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [28,28]))\n",
    "model.add(keras.layers.Dense(300, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(100, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "# 층을 하나씩 추가하지 않고 층의 리스트를 전달할 수도 있음\n",
    "# model = keras.models.Sequential([\n",
    "#     keras.layers.Flatten(input_shape = [28,28]),\n",
    "#     keras.layers.Dense(300, activation = 'relu'),\n",
    "#     keras.layers.Dense(100, activation = 'relu'),\n",
    "#     keras.layers.Dense(10, activation = 'softmax')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 구조 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 층 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.keras.layers.core.Flatten object at 0x000002C3894B6B48>, <tensorflow.python.keras.layers.core.Dense object at 0x000002C3894B83C8>, <tensorflow.python.keras.layers.core.Dense object at 0x000002C38F1CEA48>, <tensorflow.python.keras.layers.core.Dense object at 0x000002C38F1CE3C8>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.layers)\n",
    "\n",
    "hidden1 = model.layers[1] # 인덱스로 선택가능\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_1\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[2].name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 파라미터 확인하기\n",
    "- get_weights() : 가중치 확인\n",
    "- set_weights() : 가중치 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02534599 -0.04192099  0.06870961 ... -0.038114   -0.03956829\n",
      "  -0.01147286]\n",
      " [-0.06417004 -0.03617382 -0.04614795 ...  0.04610377  0.06116448\n",
      "  -0.01833124]\n",
      " [ 0.01217017 -0.04097137  0.06424288 ... -0.05396252 -0.00679654\n",
      "   0.05566017]\n",
      " ...\n",
      " [-0.02627643  0.05009631  0.06108634 ...  0.00678161 -0.01065613\n",
      "  -0.04615299]\n",
      " [-0.05122529 -0.0381493  -0.00525085 ...  0.06820393 -0.02921939\n",
      "  -0.07296768]\n",
      " [ 0.00825323 -0.04135925  0.00708894 ...  0.02245706 -0.01231481\n",
      "   0.04264469]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "weights, biases = hidden1.get_weights()\n",
    "print(weights)\n",
    "print(biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 300)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(weights.shape)\n",
    "print(biases.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 컴파일\n",
    "- .compile() 메서드를 호출하여 손실함수와 옵티마이저 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "             optimizer = 'sgd',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 클래스가 배타적이므로 sparse_categorical_crossentropy 사용\n",
    "- 만약 클래스별 확률을 가지고 있다면(원핫벡터) categorical_crossentropy 손실 사용\n",
    "- if 이진분류, softmax -> sigmoid, binary_crossentropy 손실 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 훈련과 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 1.1554 - accuracy: 0.6481 - val_loss: 0.8025 - val_accuracy: 0.7400\n",
      "Epoch 2/30\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.7085 - accuracy: 0.7675 - val_loss: 0.6500 - val_accuracy: 0.7844\n",
      "Epoch 3/30\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6153 - accuracy: 0.7931 - val_loss: 0.5926 - val_accuracy: 0.8010\n",
      "Epoch 4/30\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.5670 - accuracy: 0.8079 - val_loss: 0.5679 - val_accuracy: 0.8053\n",
      "Epoch 5/30\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.5367 - accuracy: 0.8162 - val_loss: 0.5370 - val_accuracy: 0.8155\n",
      "Epoch 6/30\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5109 - accuracy: 0.8234 - val_loss: 0.5886 - val_accuracy: 0.7946\n",
      "Epoch 7/30\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4924 - accuracy: 0.8269 - val_loss: 0.5564 - val_accuracy: 0.7974\n",
      "Epoch 8/30\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4750 - accuracy: 0.8329 - val_loss: 0.4970 - val_accuracy: 0.8269\n",
      "Epoch 9/30\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4651 - accuracy: 0.8374 - val_loss: 0.4795 - val_accuracy: 0.8315\n",
      "Epoch 10/30\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4457 - accuracy: 0.8438 - val_loss: 0.5054 - val_accuracy: 0.8154\n",
      "Epoch 11/30\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4356 - accuracy: 0.8469 - val_loss: 0.4583 - val_accuracy: 0.8403\n",
      "Epoch 12/30\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4317 - accuracy: 0.8473 - val_loss: 0.4679 - val_accuracy: 0.8351\n",
      "Epoch 13/30\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4194 - accuracy: 0.8521 - val_loss: 0.4623 - val_accuracy: 0.8411\n",
      "Epoch 14/30\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4075 - accuracy: 0.8574 - val_loss: 0.4706 - val_accuracy: 0.8295\n",
      "Epoch 15/30\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4019 - accuracy: 0.8594 - val_loss: 0.4952 - val_accuracy: 0.8242\n",
      "Epoch 16/30\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3957 - accuracy: 0.8597 - val_loss: 0.4458 - val_accuracy: 0.8434\n",
      "Epoch 17/30\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3870 - accuracy: 0.8654 - val_loss: 0.4411 - val_accuracy: 0.8426\n",
      "Epoch 18/30\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3820 - accuracy: 0.8646 - val_loss: 0.4761 - val_accuracy: 0.8269\n",
      "Epoch 19/30\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3748 - accuracy: 0.8675 - val_loss: 0.4386 - val_accuracy: 0.8470\n",
      "Epoch 20/30\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3676 - accuracy: 0.8682 - val_loss: 0.4190 - val_accuracy: 0.8519\n",
      "Epoch 21/30\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3640 - accuracy: 0.8747 - val_loss: 0.4259 - val_accuracy: 0.8520\n",
      "Epoch 22/30\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3608 - accuracy: 0.8743 - val_loss: 0.4153 - val_accuracy: 0.8543\n",
      "Epoch 23/30\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3506 - accuracy: 0.8742 - val_loss: 0.4519 - val_accuracy: 0.8401\n",
      "Epoch 24/30\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3469 - accuracy: 0.8795 - val_loss: 0.4187 - val_accuracy: 0.8539\n",
      "Epoch 25/30\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3379 - accuracy: 0.8819 - val_loss: 0.4170 - val_accuracy: 0.8548\n",
      "Epoch 26/30\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3349 - accuracy: 0.8866 - val_loss: 0.4399 - val_accuracy: 0.8496\n",
      "Epoch 27/30\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3315 - accuracy: 0.8820 - val_loss: 0.4052 - val_accuracy: 0.8591\n",
      "Epoch 28/30\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3274 - accuracy: 0.8858 - val_loss: 0.4013 - val_accuracy: 0.8591\n",
      "Epoch 29/30\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3225 - accuracy: 0.8888 - val_loss: 0.4249 - val_accuracy: 0.8544\n",
      "Epoch 30/30\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3193 - accuracy: 0.8841 - val_loss: 0.4468 - val_accuracy: 0.8411\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 30,  # epoch 디폴트 : 1\n",
    "                   validation_data = (X_valid, y_valid)) # valid data는 선택사항"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if 클래스가 불균형, class_weight 매개변수 지정하는게 좋음 (적게 등장하는 클래스는 높은 가중치를 많이 등장하는 클래스는 낮은 가중치를 부여)\n",
    "\n",
    "\n",
    "- if 샘플별로 가중치를 부여하고 싶다면, sample_weight 매개변수 지정(class_weight와 sample_weight를 곱하여 사용됨)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습곡선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize = (8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.8307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.474366158246994, 0.8306999802589417]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.11, 0.02, 0.79],\n",
       "       [0.  , 0.  , 0.75, 0.  , 0.01, 0.  , 0.23, 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-25-81ace37e545f>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_new) # np.argmax(model.predict(x), axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 시퀀셜 API를 사용하여 회귀용 다층 퍼셉트론 만들기\n",
    "- 출력층이 활성화 함수가 없는 하나의 뉴런, 손실함수로 MSE 사용\n",
    "- 이 데이터에는 잡음이 많아 뉴런 수 적은 은닉층 하나만 사용(과대적합 방지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing # 캘리포니아 주택가격\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = \\\n",
    "    train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케이링\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation  = 'relu', input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = 'sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1262 - val_loss: 0.6816\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5997 - val_loss: 0.5456\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5355 - val_loss: 0.5122\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4774 - val_loss: 0.4880\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4577 - val_loss: 0.4787\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4475 - val_loss: 0.4626\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4363 - val_loss: 0.4580\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4263 - val_loss: 0.4513\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 938us/step - loss: 0.4185 - val_loss: 0.4416\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4082 - val_loss: 0.4376\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4023 - val_loss: 0.4420\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3979 - val_loss: 0.4279\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.4233\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3892 - val_loss: 0.4325\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.4162\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3791 - val_loss: 0.4163\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 0.4153\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3745 - val_loss: 0.4106\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.371 - 0s 1ms/step - loss: 0.3712 - val_loss: 0.4038\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3669 - val_loss: 0.4048\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 5.0980\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 함수형 API를 사용해 복잡한 모델 만들기\n",
    "- Sequential 모델은 널리 사용되지만 입력과 출력이 여러 개거나 더 복잡한 네트워크 토폴로지를 갖는 신경망을 만들기 위해서는 함수형 API를 사용해야\n",
    "#### 1) 와이드 & 딥 신경망\n",
    "![title](img/10_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape = X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation = 'relu')(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation = 'relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs = [input_], outputs = [output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 우선, keras.layers.Input를 이용하여 input 객체 만들어야! shape과 dtype을 포함하여 모델의 입력을 정의(한 모델은 여러개의 입력을 가질 수 있음)\n",
    "- keras.layers.Concatenate를 이용하여 두번째 은닉층의 출력과 입력을 연결하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 여러개의 입력 다루기\n",
    "![title](img/10_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape = [5], name = 'wide_input')\n",
    "input_B = keras.layers.Input(shape = [6], name = 'deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation = 'relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation = 'relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name = 'output')(concat)\n",
    "model = keras.Model(inputs = [input_A, input_B], outputs = [output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fit() 메서드를 호출할 때 X_train -> (X_train_A, X_train_B) 튜플로 전달해야"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',optimizer = keras.optimizers.SGD(lr = 1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A, X_train_B = X_train[:,:5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:,:5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:,:5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 2.0840 - val_loss: 0.9590\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7917 - val_loss: 0.7469\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6878 - val_loss: 0.6951\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6450 - val_loss: 0.6635\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6186 - val_loss: 0.6393\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5969 - val_loss: 0.6190\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5779 - val_loss: 0.5993\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5642 - val_loss: 0.5853\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5496 - val_loss: 0.5712\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5398 - val_loss: 0.5617\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5294 - val_loss: 0.5506\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5209 - val_loss: 0.5421\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5136 - val_loss: 0.5375\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.5073 - val_loss: 0.5286\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5017 - val_loss: 0.5341\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4972 - val_loss: 0.5196\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4939 - val_loss: 0.5161\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4906 - val_loss: 0.5171\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4866 - val_loss: 0.5088\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4833 - val_loss: 0.5074\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((X_train_A, X_train_B), y_train, epochs = 20,\n",
    "                   validation_data = ((X_valid_A, X_valid_B), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4735\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) 여러개의 출력이 필요한 경우\n",
    "- ex) 여러 출력이 필요한 경우, 다중 작업 분류(표정분류 + 안경유무), 규제 기법으로 사용(보조 출력을 사용해 하위 네트워크가 나머지 네트워크에 의존하지 않고 그 자체로 유용한 것을 학습하는지 확인)\n",
    "<img src=\"img/10_3.png\" width=\"300\" height=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층까지는 이전과 동일\n",
    "output = keras.layers.Dense(1, name = 'main_output')(concat)\n",
    "aux_output = keras.layers.Dense(1, name = 'aux_output')(hidden2)\n",
    "model = keras.Model(inputs = [input_A, input_B], outputs = [output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=['mse','mse'], loss_weights = [0.9, 0.1], optimizer = 'sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9711 - main_output_loss: 0.8782 - aux_output_loss: 1.8067 - val_loss: 0.6124 - val_main_output_loss: 0.5462 - val_aux_output_loss: 1.2075\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5506 - main_output_loss: 0.4914 - aux_output_loss: 1.0832 - val_loss: 0.5385 - val_main_output_loss: 0.4884 - val_aux_output_loss: 0.9893\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5075 - main_output_loss: 0.4630 - aux_output_loss: 0.9083 - val_loss: 0.5133 - val_main_output_loss: 0.4748 - val_aux_output_loss: 0.8602\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5148 - main_output_loss: 0.4832 - aux_output_loss: 0.8000 - val_loss: 0.5067 - val_main_output_loss: 0.4766 - val_aux_output_loss: 0.7783\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4888 - main_output_loss: 0.4625 - aux_output_loss: 0.7259 - val_loss: 0.4846 - val_main_output_loss: 0.4583 - val_aux_output_loss: 0.7218\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4595 - main_output_loss: 0.4350 - aux_output_loss: 0.6800 - val_loss: 0.4785 - val_main_output_loss: 0.4552 - val_aux_output_loss: 0.6885\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4502 - main_output_loss: 0.4280 - aux_output_loss: 0.6502 - val_loss: 0.4675 - val_main_output_loss: 0.4458 - val_aux_output_loss: 0.6622\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4464 - main_output_loss: 0.4261 - aux_output_loss: 0.6300 - val_loss: 0.4580 - val_main_output_loss: 0.4377 - val_aux_output_loss: 0.6402\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4336 - main_output_loss: 0.4141 - aux_output_loss: 0.6097 - val_loss: 0.4484 - val_main_output_loss: 0.4289 - val_aux_output_loss: 0.6232\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4270 - main_output_loss: 0.4085 - aux_output_loss: 0.5938 - val_loss: 0.4417 - val_main_output_loss: 0.4232 - val_aux_output_loss: 0.6077\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4211 - main_output_loss: 0.4034 - aux_output_loss: 0.5804 - val_loss: 0.4398 - val_main_output_loss: 0.4224 - val_aux_output_loss: 0.5971\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4138 - main_output_loss: 0.3967 - aux_output_loss: 0.5682 - val_loss: 0.4267 - val_main_output_loss: 0.4092 - val_aux_output_loss: 0.5838\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4304 - main_output_loss: 0.4162 - aux_output_loss: 0.5576 - val_loss: 0.4371 - val_main_output_loss: 0.4217 - val_aux_output_loss: 0.5762\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4031 - main_output_loss: 0.3871 - aux_output_loss: 0.5472 - val_loss: 0.4227 - val_main_output_loss: 0.4069 - val_aux_output_loss: 0.5654\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3991 - main_output_loss: 0.3838 - aux_output_loss: 0.5369 - val_loss: 0.4144 - val_main_output_loss: 0.3988 - val_aux_output_loss: 0.5553\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3897 - main_output_loss: 0.3745 - aux_output_loss: 0.5268 - val_loss: 0.4074 - val_main_output_loss: 0.3923 - val_aux_output_loss: 0.5430\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3848 - main_output_loss: 0.3700 - aux_output_loss: 0.5181 - val_loss: 0.4009 - val_main_output_loss: 0.3862 - val_aux_output_loss: 0.5332\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3823 - main_output_loss: 0.3680 - aux_output_loss: 0.5109 - val_loss: 0.3974 - val_main_output_loss: 0.3834 - val_aux_output_loss: 0.5242\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3782 - main_output_loss: 0.3643 - aux_output_loss: 0.5037 - val_loss: 0.3902 - val_main_output_loss: 0.3768 - val_aux_output_loss: 0.5115\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3731 - main_output_loss: 0.3597 - aux_output_loss: 0.4944 - val_loss: 0.3847 - val_main_output_loss: 0.3712 - val_aux_output_loss: 0.5065\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B],[y_train, y_train], epochs = 20,\n",
    "                   validation_data = ([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3535 - main_output_loss: 0.3394 - aux_output_loss: 0.4798\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 서브클래싱 API로 동적 모델 만들기\n",
    "- 시퀀셜 API와 함수형 API는 모두 선언적(사용할 층과 연결방식을 먼저 정의해야)<br>\n",
    "    \\- 모델 저장, 복사, 공유, 구조 분석 쉬움. 프레임워크 크기 짐작하고 에러를 일찍 발견할 수 있음. but, 정적\n",
    "    \n",
    "    \n",
    "- 반복문을 포함하고 다양한 크기를 다루거나 조건문을 가지는 등 여러가지 동적구조를 필요로 하는 모델(명령형(imperative) 프로그래밍 필요) -> 서브클래싱 API<br><br>\n",
    "=> Model 클래스를 상속하여 생성자 안에서 필요한 층 만들기<br>\n",
    "=> call() 메서드 안에서 수행하려는 연산 기술"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation='relu',**kwargs):\n",
    "        super().__init__(**kwargs) # 표준 매개변수 처리\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input 클래스의 객체를 만들 필요 x, 대신 call() 메서드의 input 매개변수를 사용\n",
    "- call() 메서드 안에서느 for문, if문 등 저수준 연산가능\n",
    "- But, 구조를 쉽게 분석하거나 모델 저장 및 복사 못함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 모델 저장과 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 서브클래싱 모델에서는 X -> save_weights()와 load_weights()를 통해 파라미터만 저장 복원가능 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 콜백 사용하기\n",
    "- callbacks 매개변수를 사용하여 훈련의 시작이나 끝에 호출할 객체리스트 저장, 에포크의 시작/끝, 각 배치 전후에 호출가능<br>\n",
    "    ex) ModelCheckpoint는 훈련 중 일정 간격으로 체크포인트 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4068\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4029\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4084\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3968\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3985\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3909\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3877\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3847\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3825\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3802\n"
     ]
    }
   ],
   "source": [
    "# [..] 모델 만들고 컴파일하기(시퀀스 모델이용)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_model.h5') # 모델저장경로\n",
    "history = model.fit(X_train, y_train, epochs = 10, callbacks = [checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ModelCheckpoint에서 save_best_only=True를 지정하면 최상의 검증 세트 점수에서만 모델저장 -> 과대적합 걱정 x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 일정한 간격으로 모델의 체크 포인트 저장\n",
    "- ModelCheckpoint의 save_best_only 옵션 : 최상의 검증 세트 점수의 모델만 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('my_keras_model.h5')\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_model.h5',\n",
    "                                               save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3799 - val_loss: 0.4015\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3801 - val_loss: 0.4017\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3750 - val_loss: 0.3975\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3723 - val_loss: 0.3937\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3731 - val_loss: 0.4039\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3885 - val_loss: 0.3965\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3763 - val_loss: 0.3893\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3664 - val_loss: 0.3894\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3633 - val_loss: 0.3851\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3629 - val_loss: 0.3827\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 10,\n",
    "                   validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 조기 종료 구현하기 - EarlyStopping 콜백"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 10, \n",
    "                                               restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3671 - val_loss: 0.3872\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3601 - val_loss: 0.3821\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3610 - val_loss: 0.3819\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3559 - val_loss: 0.3821\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3600 - val_loss: 0.3815\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3571 - val_loss: 0.3870\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3524 - val_loss: 0.3865\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3534 - val_loss: 0.3770\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3519 - val_loss: 0.3782\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3602 - val_loss: 0.3880\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3592 - val_loss: 0.3779\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3940 - val_loss: 0.3854\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3597 - val_loss: 0.3835\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3615 - val_loss: 0.3698\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3533 - val_loss: 0.3709\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3469 - val_loss: 0.3693\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3705 - val_loss: 0.3668\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3623 - val_loss: 0.3850\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3492 - val_loss: 0.3709\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3430 - val_loss: 0.3702\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3431 - val_loss: 0.3832\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3422 - val_loss: 0.3684\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3408 - val_loss: 0.4002\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3465 - val_loss: 0.3677\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3400 - val_loss: 0.3596\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3393 - val_loss: 0.3634\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3383 - val_loss: 0.3608\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3460 - val_loss: 0.3653\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3510 - val_loss: 0.3587\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3347 - val_loss: 0.3592\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3329 - val_loss: 0.3538\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3343 - val_loss: 0.3567\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3329 - val_loss: 0.3538\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3298 - val_loss: 0.3570\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3317 - val_loss: 0.3648\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3529 - val_loss: 0.3617\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3467 - val_loss: 0.3667\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3306 - val_loss: 0.3498\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3283 - val_loss: 0.3539\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3458 - val_loss: 0.3519\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3404 - val_loss: 0.3709\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3454 - val_loss: 0.3568\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3286 - val_loss: 0.3538\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3396 - val_loss: 0.3548\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3347 - val_loss: 0.3513\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3253 - val_loss: 0.3498\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3318 - val_loss: 0.3524\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3270 - val_loss: 0.3474\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3267 - val_loss: 0.3506\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3283 - val_loss: 0.3488\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3236 - val_loss: 0.3518\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3232 - val_loss: 0.3546\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3248 - val_loss: 0.3487\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3236 - val_loss: 0.3790\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3246 - val_loss: 0.3457\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3296 - val_loss: 0.3468\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3262 - val_loss: 0.3486\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3228 - val_loss: 0.3518\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3321 - val_loss: 0.3564\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3197 - val_loss: 0.3439\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3463 - val_loss: 0.3550\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3254 - val_loss: 0.3545\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3236 - val_loss: 0.4008\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3345 - val_loss: 0.3435\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3238 - val_loss: 0.3603\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3269 - val_loss: 0.3448\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3199 - val_loss: 0.3641\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3331 - val_loss: 0.3460\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3204 - val_loss: 0.3449\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3200 - val_loss: 0.3402\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3165 - val_loss: 0.3401\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3212 - val_loss: 0.3432\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3232 - val_loss: 0.3406\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3165 - val_loss: 0.3372\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3226 - val_loss: 0.3452\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3153 - val_loss: 0.3409\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3190 - val_loss: 0.3434\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3200 - val_loss: 0.3419\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3377 - val_loss: 0.3477\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3169 - val_loss: 0.3353\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3202 - val_loss: 0.3860\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3277 - val_loss: 0.3639\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3227 - val_loss: 0.3541\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3170 - val_loss: 0.3365\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3144 - val_loss: 0.3540\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3230 - val_loss: 0.3410\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3189 - val_loss: 0.3402\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3127 - val_loss: 0.3391\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3112 - val_loss: 0.3356\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3121 - val_loss: 0.3345\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3117 - val_loss: 0.3368\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3119 - val_loss: 0.3381\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3130 - val_loss: 0.3394\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3147 - val_loss: 0.3371\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3121 - val_loss: 0.3344\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3105 - val_loss: 0.3481\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3307 - val_loss: 0.3391\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3208 - val_loss: 0.3399\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3154 - val_loss: 0.3431\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3124 - val_loss: 0.3320\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 100,\n",
    "                   validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) 사용자 정의 콜백"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 검증 손실과 훈련 손실의 비율(과대적합 감지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print('\\nval/train: {:.2f}'.format(logs['val_loss']/logs['loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 텐서보드를 사용해 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서보드 로그를 위해 루트 로그 디렉터리 정의 &\n",
    "# 실행할 때마다 날짜와 시간으로서브 디렉터리 경로를 생성하는 함수\n",
    "\n",
    "import os\n",
    "root_logdir = os.path.join(os.curdir,'my_logs')\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime('run_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.8896 - val_loss: 7.8469\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 38.4664 - val_loss: 1.6454\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5940 - val_loss: 1.1875\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4727 - val_loss: 1.0154\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4314 - val_loss: 0.9242\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.8631\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3985 - val_loss: 0.8166\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3890 - val_loss: 0.7929\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3831 - val_loss: 0.7606\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3783 - val_loss: 0.7584\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3745 - val_loss: 0.7521\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3716 - val_loss: 0.7452\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3689 - val_loss: 0.7386\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3662 - val_loss: 0.7368\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3636 - val_loss: 0.7330\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3623 - val_loss: 0.7236\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3602 - val_loss: 0.7225\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3592 - val_loss: 0.7172\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3575 - val_loss: 0.7262\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3566 - val_loss: 0.7105\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3550 - val_loss: 0.7101\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3518 - val_loss: 0.7104\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3514 - val_loss: 0.7003\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3506 - val_loss: 0.7019\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3470 - val_loss: 0.6993\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3469 - val_loss: 0.6957\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3455 - val_loss: 0.6932\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3446 - val_loss: 0.6864\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3419 - val_loss: 0.6876\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3409 - val_loss: 0.6840\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 30,\n",
    "                   validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# 프롬프트에서\n",
    "\n",
    "tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주피터안에서 텐서보드 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 24060."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_log --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create_file_write() 함수를 사용하여 텐서보드를 사용해 스칼라, 히스토그램, 이미지, 오디오, 텍스트를 시각화할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000+1):\n",
    "        tf.summary.scalar('my_scalar', np.sin(step/10) ,step=step)\n",
    "        data = (np.random.rand(100) + 2) * step / 100 # 몇몇 랜덤 데이터\n",
    "        tf.summary.histogram('my_hist', data, buckets = 50, step = step)\n",
    "        images = np.random.rand(2,32,32,3) # 32 * 32 RGB 이미지\n",
    "        tf.summary.image('my_images',images * step / 1000, step=step)\n",
    "        text = ['The step is ' + str(step), 'Its square is ' + str(step**2)]\n",
    "        tf.summary.text('my_text', text, step=step)\n",
    "        sine_wave=tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32),[1,-1,1])\n",
    "        tf.summary.audio('my_audio', audio, sample_rate = 48000, step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 파라미터 튜닝하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) GridSearchCV등을 사용하기위해 케라스 모델을 사이킷런 추정기처럼(RandomForest처럼)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden = 1, n_neurons = 30, learning_rate = 3e-3, input_shape = [8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr = learning_rate)\n",
    "    model.compile(loss='mse', optimizer = optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋 불러오기\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing # 캘리포니아 주택가격\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = \\\n",
    "    train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케이링\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_new = X_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0262 - val_loss: 0.7015\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5815 - val_loss: 0.6593\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5128 - val_loss: 1.1170\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4706 - val_loss: 0.8173\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4429 - val_loss: 0.9632\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4223 - val_loss: 0.7926\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4082 - val_loss: 0.4503\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4005 - val_loss: 0.7265\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3902 - val_loss: 0.6340\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3856 - val_loss: 0.6217\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3803 - val_loss: 0.5927\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3766 - val_loss: 0.4712\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3733 - val_loss: 0.4097\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3706 - val_loss: 0.3936\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3679 - val_loss: 0.6728\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3658 - val_loss: 0.5503\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3644 - val_loss: 0.6255\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3624 - val_loss: 0.3692\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3611 - val_loss: 0.4328\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3598 - val_loss: 0.4569\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3586 - val_loss: 0.3661\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3569 - val_loss: 0.4806\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3560 - val_loss: 0.3639\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3548 - val_loss: 0.3636\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3539 - val_loss: 0.4218\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3537 - val_loss: 0.3633\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3524 - val_loss: 0.3760\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3516 - val_loss: 0.4342\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 0.4139\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3500 - val_loss: 0.4521\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3493 - val_loss: 0.6544\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3498 - val_loss: 0.3952\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3500 - val_loss: 0.3572\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3471 - val_loss: 0.3783\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3465 - val_loss: 0.3847\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3465 - val_loss: 0.3682\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 0.3534\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3449 - val_loss: 0.3566\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3446 - val_loss: 0.3569\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3442 - val_loss: 0.4337\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3435 - val_loss: 0.3867\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3433 - val_loss: 0.3946\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.3817\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3560\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.3549\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.4442\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3407 - val_loss: 0.3657\n",
      "162/162 [==============================] - 0s 794us/step - loss: 0.3489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.1011649, 1.8644428, 2.0912337], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build_model() 함수를 사용해 KerasRegressor 클래스의 객체 만들기\n",
    "\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "\n",
    "keras_reg.fit(X_train, y_train, epochs = 100,\n",
    "             validation_data = (X_valid, y_valid),\n",
    "             callbacks = [keras.callbacks.EarlyStopping(patience = 10)])\n",
    "\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "\n",
    "y_pred = keras_reg.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 랜덤CV\n",
    "- 하이퍼파라미터가 많으므로 그리드서치보다는 랜덤CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "    'n_hidden' : [0,1,2,3],\n",
    "    'n_neurons' : np.arange(1,100),\n",
    "    'learning_rate' : reciprocal(3e-4, 3e-2) # (상호 연속적인) 랜덤 변수\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엄청 오래걸림\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter = 10, cv = 3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs = 100,\n",
    "                 validation_data = (X_valid, y_valid),\n",
    "                 callbacks = [keras.callbacks.EarlyStopping(patience = 10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RandomizedSearchCV는 k-겹 교차검증을 사용하기 때문에 validation set은 조기종료에만 사용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이외에도 Hyperopt, Sklearn-Deap과 같은 다양한 라이브러리와 서비스가 제공되며, 활발히 연구되는 영역임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
